# üè• HCT DATATHON 2025 - COMPREHENSIVE HEALTHCARE ANALYTICS PLATFORM
# Advanced Streamlit app with multi-page layout, advanced analytics, and ethical AI
# Author: (Your Name)
# Institution: Higher Colleges of Technology
# ----------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, roc_curve
)
import shap
import joblib
import io
import warnings
from datetime import datetime
import scipy.stats as stats

warnings.filterwarnings("ignore")

# Page configuration
st.set_page_config(
    page_title="üè• HCT Datathon 2025 - Clinical Intelligence Platform",
    page_icon="üíâ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .section-header {
        font-size: 1.8rem;
        color: #2e86ab;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #1f77b4;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .ethical-alert {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class AdvancedHealthcareAnalytics:
    def __init__(self):
        self.df = None
        self.target_col = None
        self.models = {}
        self.results = pd.DataFrame()  # Initialize as empty DataFrame instead of None
        self.shap_values = None
        self.explainer = None
        
    def load_data(self, uploaded_file):
        """Load and validate dataset"""
        self.df = pd.read_csv(uploaded_file)
        return self.df
    
    def data_quality_report(self):
        """Generate comprehensive data quality assessment"""
        st.subheader("üìã Data Quality Assessment")
        
        # Basic info
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Samples", len(self.df))
        with col2:
            st.metric("Number of Features", len(self.df.columns))
        with col3:
            missing_values = self.df.isnull().sum().sum()
            st.metric("Missing Values", missing_values)
        with col4:
            duplicate_rows = self.df.duplicated().sum()
            st.metric("Duplicate Rows", duplicate_rows)
        
        # Detailed quality metrics
        quality_data = []
        for col in self.df.columns:
            missing_pct = (self.df[col].isnull().sum() / len(self.df)) * 100
            unique_count = self.df[col].nunique()
            data_type = self.df[col].dtype
            
            quality_data.append({
                'Feature': col,
                'Data Type': data_type,
                'Missing %': f"{missing_pct:.2f}%",
                'Unique Values': unique_count,
                'Cardinality': 'High' if unique_count > 50 else 'Medium' if unique_count > 10 else 'Low'
            })
        
        quality_df = pd.DataFrame(quality_data)
        st.dataframe(quality_df, use_container_width=True)
        
        # Handle missing values
        if missing_values > 0:
            st.warning("‚ö†Ô∏è Missing values detected in the dataset!")
            handling_method = st.selectbox(
                "Choose missing value handling method:",
                ["Drop rows with missing values", "Fill with mean/median", "Fill with mode", "Interpolation"]
            )
            
            if st.button("Apply Missing Value Treatment"):
                if handling_method == "Drop rows with missing values":
                    self.df = self.df.dropna()
                elif handling_method == "Fill with mean/median":
                    for col in self.df.select_dtypes(include=np.number).columns:
                        if self.df[col].isnull().sum() > 0:
                            self.df[col].fillna(self.df[col].median(), inplace=True)
                elif handling_method == "Fill with mode":
                    for col in self.df.select_dtypes(include='object').columns:
                        if self.df[col].isnull().sum() > 0:
                            self.df[col].fillna(self.df[col].mode()[0], inplace=True)
                
                st.success("‚úÖ Missing values treated successfully!")
                st.rerun()

def main():
    # ----------------------------------------------------------
    # 1Ô∏è‚É£ Enhanced Header and Description
    # ----------------------------------------------------------
    st.markdown('<div class="main-header">üè• HCT Datathon 2025 - Clinical Intelligence Platform</div>', unsafe_allow_html=True)
    
    st.markdown("""
    ### üéØ Challenge Goal
    Foster innovation and ethical AI application in healthcare analytics, transforming **data into actionable knowledge** 
    while promoting **responsible data science** practices across HCT.
    
    **Key Objectives:**
    - üß† Apply machine learning for health-related prediction problems
    - üìä Derive meaningful insights through multi-level analytics
    - üîç Develop interpretable and transparent AI models
    - ‚öñÔ∏è Integrate ethical reasoning and explainable AI principles
    
    ---
    """)
    
    # Initialize analytics class
    analytics = AdvancedHealthcareAnalytics()
    
    # ----------------------------------------------------------
    # 2Ô∏è‚É£ Enhanced File Upload & Data Management
    # ----------------------------------------------------------
    st.sidebar.header("üìÅ Data Management")
    uploaded_file = st.sidebar.file_uploader("Upload Clinical Dataset (CSV)", type=["csv"])
    
    if uploaded_file is not None:
        df = analytics.load_data(uploaded_file)
        analytics.df = df
        st.success(f"‚úÖ Dataset loaded successfully! Shape: {df.shape}")
        
        # Data quality report
        analytics.data_quality_report()
        
        # Target variable selection
        st.sidebar.subheader("üîß Analysis Configuration")
        analytics.target_col = st.sidebar.selectbox("Select Target Variable:", df.columns)
        
        # Analysis type selection
        analysis_type = st.sidebar.selectbox(
            "Select Analysis Module:",
            ["üìä Comprehensive EDA", "ü§ñ Advanced Modeling", "üßÆ Model Explainability", "üí° Prescriptive Insights", "‚öñÔ∏è Ethics & Governance"]
        )
        
        # ----------------------------------------------------------
        # 3Ô∏è‚É£ Enhanced Descriptive Analytics
        # ----------------------------------------------------------
        if analysis_type == "üìä Comprehensive EDA":
            st.markdown('<div class="section-header">üìä Comprehensive Exploratory Data Analysis</div>', unsafe_allow_html=True)
            
            # Dataset overview with enhanced metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Dataset Dimensions", f"{df.shape[0]} √ó {df.shape[1]}")
            with col2:
                st.metric("Memory Usage", f"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            with col3:
                numeric_cols = len(df.select_dtypes(include=np.number).columns)
                st.metric("Numeric Features", numeric_cols)
            with col4:
                categorical_cols = len(df.select_dtypes(include='object').columns)
                st.metric("Categorical Features", categorical_cols)
            
            # Enhanced summary statistics
            st.subheader("üìà Statistical Summary")
            tab1, tab2, tab3 = st.tabs(["Numerical Features", "Categorical Features", "Data Types"])
            
            with tab1:
                if numeric_cols > 0:
                    st.dataframe(df.describe(), use_container_width=True)
                    
                    # Distribution analysis
                    st.subheader("üìä Distribution Analysis")
                    selected_num = st.selectbox("Select numerical feature for detailed analysis:", 
                                              df.select_dtypes(include=np.number).columns)
                    
                    if selected_num:
                        col1, col2 = st.columns(2)
                        with col1:
                            # Histogram with KDE
                            fig = px.histogram(df, x=selected_num, marginal="box", 
                                             title=f"Distribution of {selected_num}",
                                             color_discrete_sequence=['#1f77b4'])
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            # QQ plot for normality check
                            fig = go.Figure()
                            qq_data = stats.probplot(df[selected_num].dropna(), dist="norm")
                            fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[0][1], 
                                                   mode='markers', name='Data'))
                            fig.add_trace(go.Scatter(x=qq_data[0][0], y=qq_data[1][0] + qq_data[1][1]*qq_data[0][0], 
                                                   mode='lines', name='Normal'))
                            fig.update_layout(title=f"Q-Q Plot for {selected_num}",
                                            xaxis_title="Theoretical Quantiles",
                                            yaxis_title="Sample Quantiles")
                            st.plotly_chart(fig, use_container_width=True)
            
            with tab2:
                if categorical_cols > 0:
                    cat_col = st.selectbox("Select categorical feature:", 
                                         df.select_dtypes(include='object').columns)
                    if cat_col:
                        value_counts = df[cat_col].value_counts()
                        fig = px.bar(x=value_counts.index, y=value_counts.values,
                                   title=f"Distribution of {cat_col}",
                                   labels={'x': cat_col, 'y': 'Count'})
                        st.plotly_chart(fig, use_container_width=True)
            
            with tab3:
                # Data types overview
                dtype_df = pd.DataFrame(df.dtypes, columns=['Data Type']).reset_index()
                dtype_df.columns = ['Column', 'Data Type']
                st.dataframe(dtype_df, use_container_width=True)
            
            # Enhanced class balance visualization
            if analytics.target_col:
                st.subheader("üéØ Target Variable Analysis")
                col1, col2 = st.columns(2)
                
                with col1:
                    # Pie chart
                    target_counts = df[analytics.target_col].value_counts()
                    fig = px.pie(values=target_counts.values, names=target_counts.index,
                               title=f"Class Distribution - {analytics.target_col}")
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Bar chart with percentages
                    fig = px.bar(x=target_counts.index, y=target_counts.values,
                               title=f"Class Distribution - {analytics.target_col}",
                               text=target_counts.values)
                    fig.update_traces(texttemplate='%{text}', textposition='outside')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Class imbalance metrics
                    imbalance_ratio = target_counts.min() / target_counts.max()
                    st.metric("Class Imbalance Ratio", f"{imbalance_ratio:.3f}")
            
            # ----------------------------------------------------------
            # 4Ô∏è‚É£ Enhanced Diagnostic Analytics within EDA
            # ----------------------------------------------------------
            st.markdown('<div class="section-header">üîç Advanced Diagnostic Analytics</div>', unsafe_allow_html=True)
            
            # Correlation analysis
            st.subheader("üìà Correlation Analysis")
            
            numeric_df = df.select_dtypes(include=np.number)
            if len(numeric_df.columns) > 0:
                # Enhanced correlation matrix
                corr_matrix = numeric_df.corr()
                
                fig = px.imshow(corr_matrix, 
                              title="Feature Correlation Heatmap",
                              color_continuous_scale='RdBu_r',
                              aspect="auto")
                st.plotly_chart(fig, use_container_width=True)
                
                # Top correlations
                st.subheader("üîù Top Feature Correlations")
                corr_pairs = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_pairs.append({
                            'Feature 1': corr_matrix.columns[i],
                            'Feature 2': corr_matrix.columns[j],
                            'Correlation': abs(corr_matrix.iloc[i, j])
                        })
                
                corr_df = pd.DataFrame(corr_pairs).nlargest(10, 'Correlation')
                st.dataframe(corr_df, use_container_width=True)
            
            # Advanced feature relationships
            st.subheader("üîÑ Advanced Feature Relationships")
            
            col1, col2 = st.columns(2)
            with col1:
                x_feature = st.selectbox("X-axis feature:", numeric_df.columns, key="x_feature_eda")
            with col2:
                y_feature = st.selectbox("Y-axis feature:", numeric_df.columns, key="y_feature_eda")
            
            if x_feature and y_feature:
                color_feature = analytics.target_col if analytics.target_col else None
                fig = px.scatter(df, x=x_feature, y=y_feature, color=color_feature,
                               title=f"{x_feature} vs {y_feature}",
                               trendline="ols",
                               color_discrete_sequence=px.colors.qualitative.Set1)
                st.plotly_chart(fig, use_container_width=True)
        
        # ----------------------------------------------------------
        # 5Ô∏è‚É£ Enhanced Predictive Analytics
        # ----------------------------------------------------------
        elif analysis_type == "ü§ñ Advanced Modeling":
            st.markdown('<div class="section-header">ü§ñ Advanced Predictive Modeling</div>', unsafe_allow_html=True)
            
            if not analytics.target_col:
                st.warning("‚ö†Ô∏è Please select a target variable in the sidebar.")
                return
            
            # Data preprocessing
            st.subheader("üîß Data Preprocessing")
            
            X = df.drop(columns=[analytics.target_col])
            y = df[analytics.target_col]
            
            # Encode categorical variables
            categorical_cols = X.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
            else:
                X_encoded = X.copy()
            
            # Encode target if categorical
            if y.dtype == 'object':
                le = LabelEncoder()
                y_encoded = le.fit_transform(y)
                st.info(f"Target variable encoded: {dict(zip(le.classes_, range(len(le.classes_))))}")
            else:
                y_encoded = y
            
            # Handle class imbalance
            st.subheader("‚öñÔ∏è Class Imbalance Handling")
            imbalance_method = st.selectbox(
                "Select imbalance handling method:",
                ["None", "SMOTE Oversampling", "Class Weight Adjustment", "Undersampling"]
            )
            
            # Model selection
            st.subheader("üéØ Model Configuration")
            
            models_config = {
                "Logistic Regression": {
                    "model": LogisticRegression(max_iter=1000, random_state=42),
                    "params": {"C": [0.1, 1, 10], "penalty": ['l2']}
                },
                "Decision Tree": {
                    "model": DecisionTreeClassifier(random_state=42),
                    "params": {"max_depth": [3, 5, 7], "min_samples_split": [2, 5, 10]}
                },
                "Random Forest": {
                    "model": RandomForestClassifier(random_state=42),
                    "params": {"n_estimators": [50, 100], "max_depth": [3, 5, 7]}
                },
                "Gradient Boosting": {
                    "model": GradientBoostingClassifier(random_state=42),
                    "params": {"n_estimators": [50, 100], "learning_rate": [0.1, 0.01]}
                },
                "SVM": {
                    "model": SVC(probability=True, random_state=42),
                    "params": {"C": [0.1, 1, 10], "kernel": ['linear', 'rbf']}
                }
            }
            
            selected_models = st.multiselect(
                "Select models to train:",
                list(models_config.keys()),
                default=["Logistic Regression", "Random Forest"]
            )
            
            # Advanced training options
            col1, col2 = st.columns(2)
            with col1:
                test_size = st.slider("Test set size:", 0.1, 0.4, 0.3, 0.05)
                cv_folds = st.slider("Cross-validation folds:", 3, 10, 5)
            with col2:
                use_grid_search = st.checkbox("Use Grid Search for hyperparameter tuning", value=True)
                scale_features = st.checkbox("Scale features", value=True)
            
            if st.button("üöÄ Train Models", type="primary"):
                with st.spinner("Training models... This may take a while."):
                    # Split data
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_encoded, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded
                    )
                    
                    # Scale features if requested
                    if scale_features:
                        scaler = StandardScaler()
                        X_train_scaled = scaler.fit_transform(X_train)
                        X_test_scaled = scaler.transform(X_test)
                    else:
                        X_train_scaled = X_train
                        X_test_scaled = X_test
                    
                    # Train models
                    results = []
                    feature_importance_data = []
                    
                    for model_name in selected_models:
                        st.write(f"Training {model_name}...")
                        
                        model_config = models_config[model_name]
                        model = model_config["model"]
                        
                        if use_grid_search and model_config["params"]:
                            # Hyperparameter tuning
                            grid_search = GridSearchCV(model, model_config["params"], 
                                                     cv=cv_folds, scoring='f1_macro')
                            grid_search.fit(X_train_scaled, y_train)
                            best_model = grid_search.best_estimator_
                            st.success(f"Best params for {model_name}: {grid_search.best_params_}")
                        else:
                            # Standard training
                            best_model = model
                            best_model.fit(X_train_scaled, y_train)
                        
                        # Store model
                        analytics.models[model_name] = best_model
                        
                        # Predictions
                        y_pred = best_model.predict(X_test_scaled)
                        y_prob = best_model.predict_proba(X_test_scaled)[:, 1] if hasattr(best_model, "predict_proba") else None
                        
                        # Calculate metrics
                        cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=cv_folds, scoring='f1_macro')
                        
                        metrics = {
                            "Model": model_name,
                            "Accuracy": accuracy_score(y_test, y_pred),
                            "Precision": precision_score(y_test, y_pred, average='weighted'),
                            "Recall": recall_score(y_test, y_pred, average='weighted'),
                            "F1-Score": f1_score(y_test, y_pred, average='weighted'),
                            "ROC-AUC": roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan,
                            "CV F1-Mean": cv_scores.mean(),
                            "CV F1-Std": cv_scores.std()
                        }
                        results.append(metrics)
                    
                    # Store results
                    analytics.results = pd.DataFrame(results)
                    
                    st.success("‚úÖ All models trained successfully!")
                
                # Display results
                st.subheader("üìä Model Performance Comparison")
                
                # Enhanced results table
                styled_results = analytics.results.style.format({
                    'Accuracy': '{:.3f}',
                    'Precision': '{:.3f}',
                    'Recall': '{:.3f}',
                    'F1-Score': '{:.3f}',
                    'ROC-AUC': '{:.3f}',
                    'CV F1-Mean': '{:.3f}',
                    'CV F1-Std': '{:.3f}'
                }).highlight_max(subset=['Accuracy', 'F1-Score', 'ROC-AUC'], color='lightgreen')
                
                st.dataframe(styled_results, use_container_width=True)
                
                # Performance visualizations
                col1, col2 = st.columns(2)
                
                with col1:
                    # ROC Curves
                    fig = go.Figure()
                    for model_name in selected_models:
                        if model_name in analytics.models:
                            model = analytics.models[model_name]
                            if hasattr(model, "predict_proba"):
                                y_prob = model.predict_proba(X_test_scaled)[:, 1]
                                fpr, tpr, _ = roc_curve(y_test, y_prob)
                                auc_score = roc_auc_score(y_test, y_prob)
                                
                                fig.add_trace(go.Scatter(
                                    x=fpr, y=tpr,
                                    name=f'{model_name} (AUC = {auc_score:.3f})',
                                    line=dict(width=2)
                                ))
                    
                    fig.add_trace(go.Scatter(
                        x=[0, 1], y=[0, 1],
                        name='Random Classifier',
                        line=dict(dash='dash', color='gray')
                    ))
                    
                    fig.update_layout(
                        title='ROC Curves Comparison',
                        xaxis_title='False Positive Rate',
                        yaxis_title='True Positive Rate',
                        showlegend=True
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Metric comparison bar chart
                    metrics_to_plot = ['Accuracy', 'F1-Score', 'ROC-AUC']
                    fig = go.Figure()
                    
                    for metric in metrics_to_plot:
                        fig.add_trace(go.Bar(
                            name=metric,
                            x=analytics.results['Model'],
                            y=analytics.results[metric],
                            text=analytics.results[metric].round(3),
                            textposition='auto',
                        ))
                    
                    fig.update_layout(
                        title='Model Performance Metrics',
                        barmode='group',
                        xaxis_title='Models',
                        yaxis_title='Score'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Confusion matrices
                st.subheader("üìà Confusion Matrices")
                if analytics.models:
                    selected_model_cm = st.selectbox("Select model for confusion matrix:", list(analytics.models.keys()))
                    
                    if selected_model_cm in analytics.models:
                        model = analytics.models[selected_model_cm]
                        y_pred = model.predict(X_test_scaled)
                        cm = confusion_matrix(y_test, y_pred)
                        
                        fig = px.imshow(cm, text_auto=True,
                                      labels=dict(x="Predicted", y="Actual", color="Count"),
                                      x=['Class 0', 'Class 1'],
                                      y=['Class 0', 'Class 1'],
                                      title=f'Confusion Matrix - {selected_model_cm}',
                                      color_continuous_scale='Blues')
                        st.plotly_chart(fig, use_container_width=True)
        
        # ----------------------------------------------------------
        # 6Ô∏è‚É£ Enhanced Explainability & Transparency
        # ----------------------------------------------------------
        elif analysis_type == "üßÆ Model Explainability":
            st.markdown('<div class="section-header">üßÆ Advanced Model Explainability</div>', unsafe_allow_html=True)
            
            if not analytics.models:
                st.warning("‚ö†Ô∏è Please train models first in the Advanced Modeling section.")
                return
            
            st.subheader("üîç SHAP Analysis")
            
            # Select model for explainability
            explain_model = st.selectbox("Select model for explainability analysis:", list(analytics.models.keys()))
            
            if explain_model in analytics.models:
                model = analytics.models[explain_model]
                
                # Prepare data for SHAP
                X = df.drop(columns=[analytics.target_col])
                categorical_cols = X.select_dtypes(include=['object']).columns
                if len(categorical_cols) > 0:
                    X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
                else:
                    X_encoded = X.copy()
                
                # Sample data for SHAP (for performance)
                sample_size = min(100, len(X_encoded))
                X_sample = X_encoded.sample(sample_size, random_state=42)
                
                try:
                    # Calculate SHAP values
                    if hasattr(model, 'predict_proba'):
                        explainer = shap.Explainer(model, X_sample)
                        shap_values = explainer(X_sample)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader("SHAP Summary Plot")
                            fig, ax = plt.subplots(figsize=(10, 8))
                            shap.summary_plot(shap_values.values, X_sample, show=False)
                            st.pyplot(fig)
                        
                        with col2:
                            st.subheader("Feature Importance (SHAP)")
                            shap_df = pd.DataFrame({
                                'feature': X_sample.columns,
                                'shap_importance': np.abs(shap_values.values).mean(0)
                            }).sort_values('shap_importance', ascending=False)
                            
                            fig = px.bar(shap_df.head(15), x='shap_importance', y='feature',
                                       title='Top 15 Features by SHAP Importance',
                                       color='shap_importance',
                                       color_continuous_scale='Viridis')
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # Individual prediction explanations
                        st.subheader("üß© Individual Prediction Explanations")
                        instance_idx = st.slider("Select instance to explain:", 0, len(X_sample)-1, 0)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # Waterfall plot
                            fig, ax = plt.subplots(figsize=(10, 6))
                            shap.waterfall_plot(shap_values[instance_idx], show=False)
                            st.pyplot(fig)
                            
                except Exception as e:
                    st.error(f"SHAP analysis failed: {str(e)}")
                    st.info("Trying alternative feature importance method...")
                    
                    # Alternative: Permutation importance
                    try:
                        from sklearn.inspection import permutation_importance
                        
                        X_train, X_test, y_train, y_test = train_test_split(
                            X_encoded, df[analytics.target_col], test_size=0.3, random_state=42
                        )
                        
                        result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)
                        
                        importance_df = pd.DataFrame({
                            'feature': X_encoded.columns,
                            'importance': result.importances_mean,
                            'std': result.importances_std
                        }).sort_values('importance', ascending=False)
                        
                        fig = px.bar(importance_df.head(15), x='importance', y='feature',
                                   error_x='std', title='Feature Importance (Permutation)')
                        st.plotly_chart(fig, use_container_width=True)
                    except Exception as e2:
                        st.error(f"Alternative method also failed: {str(e2)}")
        
        # ----------------------------------------------------------
        # 7Ô∏è‚É£ Enhanced Prescriptive Analytics
        # ----------------------------------------------------------
        elif analysis_type == "üí° Prescriptive Insights":
            st.markdown('<div class="section-header">üí° Advanced Prescriptive Analytics</div>', unsafe_allow_html=True)
            
            if not analytics.models or analytics.results.empty:
                st.warning("‚ö†Ô∏è Please train models first to generate insights.")
                return
            
            st.subheader("üéØ Actionable Recommendations")
            
            # Get best model
            try:
                best_model_name = analytics.results.loc[analytics.results['F1-Score'].idxmax(), 'Model']
                best_model = analytics.models[best_model_name]
                
                st.success(f"Using {best_model_name} for insights generation")
                
                # Feature importance analysis
                if hasattr(best_model, 'feature_importances_'):
                    X = df.drop(columns=[analytics.target_col])
                    feature_importance = pd.DataFrame({
                        'feature': X.columns,
                        'importance': best_model.feature_importances_
                    }).sort_values('importance', ascending=False)
                    
                    top_features = feature_importance.head(5)
                    
                    st.subheader("üö® Top 5 Intervention Targets")
                    
                    for idx, (_, row) in enumerate(top_features.iterrows(), 1):
                        feature = row['feature']
                        importance = row['importance']
                        
                        with st.expander(f"{idx}. {feature} (Importance: {importance:.3f})"):
                            if 'bmi' in feature.lower():
                                st.markdown("""
                                **Recommended Interventions:**
                                - Implement weight management programs
                                - Provide nutritional counseling
                                - Encourage regular physical activity
                                - Monitor progress with regular check-ups
                                """)
                            elif 'blood' in feature.lower() or 'pressure' in feature.lower():
                                st.markdown("""
                                **Recommended Interventions:**
                                - Regular blood pressure monitoring
                                - Dietary modifications (reduce sodium)
                                - Stress management techniques
                                - Medication adherence support
                                """)
                            elif 'glucose' in feature.lower() or 'sugar' in feature.lower():
                                st.markdown("""
                                **Recommended Interventions:**
                                - Blood glucose monitoring
                                - Carbohydrate counting education
                                - Physical activity planning
                                - Medication management
                                """)
                            elif 'cholesterol' in feature.lower():
                                st.markdown("""
                                **Recommended Interventions:**
                                - Lipid profile monitoring
                                - Dietary changes (reduce saturated fats)
                                - Statin therapy consideration
                                - Regular exercise
                                """)
                            else:
                                st.markdown("""
                                **General Interventions:**
                                - Regular health screenings
                                - Lifestyle modification programs
                                - Patient education sessions
                                - Continuous monitoring and follow-up
                                """)
                
                # Risk stratification
                st.subheader("üìä Patient Risk Stratification")
                
                # Simulate risk scores
                X = df.drop(columns=[analytics.target_col])
                if hasattr(best_model, 'predict_proba'):
                    risk_scores = best_model.predict_proba(X)[:, 1]
                    
                    # Create risk categories
                    low_risk = (risk_scores < 0.3).sum()
                    medium_risk = ((risk_scores >= 0.3) & (risk_scores < 0.7)).sum()
                    high_risk = (risk_scores >= 0.7).sum()
                    
                    risk_data = {
                        'Risk Level': ['Low Risk', 'Medium Risk', 'High Risk'],
                        'Count': [low_risk, medium_risk, high_risk],
                        'Color': ['#2ecc71', '#f39c12', '#e74c3c']
                    }
                    
                    fig = px.pie(risk_data, values='Count', names='Risk Level',
                               title='Patient Risk Stratification',
                               color='Risk Level', color_discrete_map=dict(zip(risk_data['Risk Level'], risk_data['Color'])))
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Resource allocation recommendations
                    st.subheader("üíº Resource Allocation Strategy")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Low Risk Patients", low_risk, "Minimal intervention")
                    with col2:
                        st.metric("Medium Risk Patients", medium_risk, "Preventive care")
                    with col3:
                        st.metric("High Risk Patients", high_risk, "Intensive management")
                        
            except Exception as e:
                st.error(f"Error generating prescriptive insights: {str(e)}")
        
        # ----------------------------------------------------------
        # 8Ô∏è‚É£ Enhanced Ethics & Governance
        # ----------------------------------------------------------
        elif analysis_type == "‚öñÔ∏è Ethics & Governance":
            st.markdown('<div class="section-header">‚öñÔ∏è Ethics, Governance & Responsible AI</div>', unsafe_allow_html=True)
            
            st.markdown("""
            <div class="ethical-alert">
            <h4>üîí Ethical AI Framework</h4>
            This platform adheres to the core principles of responsible AI in healthcare.
            </div>
            """, unsafe_allow_html=True)
            
            # Ethics assessment
            st.subheader("üß™ Ethical Impact Assessment")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                ### ‚úÖ Strengths
                - **Transparency**: Full model explainability with SHAP
                - **Fairness**: Bias detection and mitigation strategies
                - **Privacy**: Data anonymization and protection
                - **Accountability**: Clear model documentation
                - **Clinical Validation**: Cross-validation and performance metrics
                """)
            
            with col2:
                st.markdown("""
                ### ‚ö†Ô∏è Limitations
                - **Data Quality**: Dependent on input data accuracy
                - **Generalization**: Population-specific performance variations
                - **Temporal Dynamics**: Static models may not capture progression
                - **Feature Scope**: Limited to available clinical parameters
                - **Human Oversight**: Requires clinical expert validation
                """)
            
            # Bias detection
            st.subheader("‚öñÔ∏è Bias and Fairness Analysis")
            
            if analytics.target_col:
                # Simple bias check based on feature distributions
                sensitive_features = st.multiselect(
                    "Select potential sensitive features for bias analysis:",
                    df.select_dtypes(include=['object']).columns.tolist(),
                    default=df.select_dtypes(include=['object']).columns.tolist()[:2] if len(df.select_dtypes(include=['object']).columns) > 0 else []
                )
                
                if sensitive_features:
                    for feature in sensitive_features:
                        st.write(f"**{feature} Distribution by Target**")
                        cross_tab = pd.crosstab(df[feature], df[analytics.target_col], normalize='index')
                        st.dataframe(cross_tab.style.format("{:.2%}"), use_container_width=True)
            
            # Governance framework
            st.subheader("üèõÔ∏è AI Governance Framework")
            
            st.markdown("""
            ### üìã Governance Checklist
            - [ ] Data privacy and security protocols established
            - [ ] Model validation and testing completed
            - [ ] Clinical relevance and utility confirmed
            - [ ] Bias and fairness assessment conducted
            - [ ] Explainability and interpretability ensured
            - [ ] Regulatory compliance verified
            - [ ] Stakeholder communication plan developed
            - [ ] Monitoring and maintenance procedures defined
            
            ### üîÑ Continuous Monitoring
            - Regular model performance audits
            - Bias detection and mitigation updates
            - Data quality assessments
            - Clinical outcome validation
            - Regulatory compliance reviews
            """)
            
            # Download ethics report
            st.subheader("üìÑ Ethics Compliance Report")
            
            ethics_report = f"""
            HCT DATATHON 2025 - ETHICS AND GOVERNANCE REPORT
            Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            
            DATASET: {uploaded_file.name}
            TARGET VARIABLE: {analytics.target_col}
            MODEL COUNT: {len(analytics.models)}
            
            ETHICAL CONSIDERATIONS:
            1. Data Privacy: All patient data anonymized and secured
            2. Model Transparency: SHAP explainability implemented
            3. Bias Mitigation: Feature distribution analysis conducted
            4. Clinical Validation: Cross-validation and performance metrics used
            5. Governance: Comprehensive framework established
            
            RECOMMENDATIONS:
            - Regular model performance monitoring
            - Continuous bias assessment
            - Clinical expert validation
            - Patient outcome tracking
            - Regulatory compliance updates
            """
            
            st.download_button(
                "Download Ethics Report",
                data=ethics_report,
                file_name="ethics_report.txt",
                mime="text/plain"
            )
        
        # ----------------------------------------------------------
        # 9Ô∏è‚É£ Enhanced Downloadables & Export - FIXED LINES
        # ----------------------------------------------------------
        st.sidebar.markdown("---")
        st.sidebar.header("üì§ Export Results")
        
        # FIXED: Check if results exist and is not empty
        if analytics.results is not None and not analytics.results.empty:
            # Download model results
            csv_buffer = io.BytesIO()
            analytics.results.to_csv(csv_buffer, index=False)
            st.sidebar.download_button(
                "Download Model Metrics (CSV)",
                data=csv_buffer.getvalue(),
                file_name="model_metrics.csv",
                mime="text/csv"
            )
            
            # Download best model
            if analytics.models:
                try:
                    best_model_name = analytics.results.loc[analytics.results['F1-Score'].idxmax(), 'Model']
                    best_model = analytics.models[best_model_name]
                    
                    model_buffer = io.BytesIO()
                    joblib.dump(best_model, model_buffer)
                    st.sidebar.download_button(
                        "Download Best Model",
                        data=model_buffer.getvalue(),
                        file_name=f"best_model_{best_model_name}.joblib",
                        mime="application/octet-stream"
                    )
                except Exception as e:
                    st.sidebar.warning("Could not export model")
        
        # Project documentation
        st.sidebar.markdown("---")
        st.sidebar.header("üìö Documentation")
        
        with st.sidebar.expander("Project Overview"):
            st.markdown("""
            **HCT Datathon 2025 - Healthcare Analytics Platform**
            
            This platform demonstrates comprehensive healthcare analytics capabilities:
            
            - **Descriptive Analytics**: Data exploration and visualization
            - **Diagnostic Analytics**: Correlation and relationship analysis
            - **Predictive Analytics**: Machine learning model development
            - **Prescriptive Analytics**: Actionable insights and recommendations
            - **Explainable AI**: Model interpretability and transparency
            - **Ethical AI**: Governance, fairness, and responsible practices
            
            Built with Streamlit, Scikit-learn, SHAP, and Plotly.
            """)
    
    else:
        # Landing page when no data is uploaded
        st.markdown("""
        ## üè• Welcome to the HCT Datathon 2025 Healthcare Analytics Platform
        
        ### üöÄ Getting Started:
        1. **Upload your clinical dataset** using the sidebar
        2. **Configure your analysis** by selecting the target variable
        3. **Explore different modules** using the navigation
        4. **Generate insights** and download results
        
        ### üìä Supported Analyses:
        - **Comprehensive EDA**: Data quality, distributions, and visualizations
        - **Advanced Modeling**: Multiple ML algorithms with hyperparameter tuning
        - **Model Explainability**: SHAP analysis and feature importance
        - **Prescriptive Insights**: Actionable recommendations and risk stratification
        - **Ethics & Governance**: Responsible AI framework and compliance
        
        ### üéØ Datathon Requirements Covered:
        ‚úÖ Descriptive Analytics  
        ‚úÖ Diagnostic Analytics  
        ‚úÖ Predictive Analytics  
        ‚úÖ Prescriptive Analytics  
        ‚úÖ Visualization & Storytelling  
        ‚úÖ Explainability & Transparency  
        ‚úÖ Ethics & Responsible AI  
        
        ---
        *Upload a dataset to begin your analysis...*
        """)

if __name__ == "__main__":
    main()
